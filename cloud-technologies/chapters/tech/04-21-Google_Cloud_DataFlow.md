# Google Cloud DataFlow -o-


|          |                           |
| -------- | ------------------------- |
| title    | Google Cloud DataFlow     | 
| status   | 10                        |
| section  | High level Programming    |
| keywords | High level Programming    |


     
Google Cloud DataFlow is a unified programming model that manages the
deployment, maintenance and optimization of data processes such as
batch processing, ETL etc [@www-cloud-google1]. It creates a
pipeline of tasks and dynamically allocates resources thereby
maintaining high efficiency and low latency. These capabilities make
it suitable for solving challenging big data problems
[@www-cloud-google1]. Also, google DataFlow overcomes the
performance issues faced by Hadoops Mapreduce while building
pipelines\cite{www-dataconomy}.  The performance of MapReduce started
deteriorating while facing multiple petabytes of data whereas Google
Cloud Dataflow is apparently better at handling enormous datasets
[@www-cloud-google1]. Additionally Google Dataflow can be
integrated with Cloud Storage, Cloud Pub/Sub, Cloud Datastore, Cloud
Bigtable, and BigQuery. The unified programming ability is another
noteworthy feature which uses Apache Beam SDKs to support powerful
operations like windowing and allows correctness control to be applied
to batch and stream data processes.



     
